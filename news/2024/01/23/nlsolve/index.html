<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <meta property="og:title" content="SciML: Open Source Software for Scientific Machine Learning"> <meta property="og:description" content="Open Source Software for Scientific Machine Learning"> <meta property="og:image" content="https://sciml.ai/assets/SciMLGitHubPreview.png"> <meta property="og:url" content="https://sciml.ai"> <meta name="twitter:title" content=SciML > <meta name="twitter:description" content="Open Source Software for Scientific Machine Learning"> <meta name="twitter:image" content="https://sciml.ai/assets/SciMLGitHubPreview.png"> <meta name="twitter:card" content=summary_large_image > <!-- Favicon--> <link rel=icon  type="image/x-icon" href="assets/favicon.png" /> <!-- Bootstrap icons--> <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css" rel=stylesheet  type="text/css" /> <link rel=stylesheet  href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.8.1/font/bootstrap-icons.css"> <!-- Google fonts--> <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic" rel=stylesheet  type="text/css" /> <!-- Core theme CSS (includes Bootstrap)--> <link href="./css/styles.css" rel=stylesheet  /> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/styles.css"> <link rel=stylesheet  href="/css/hypertext.css"> <link rel=icon  href="/assets/favicon.png"> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-90474609-2"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-90474609-2'); </script> <title>Why we deprecated NLsolve.jl for NonlinearSolve.jl</title> <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin=anonymous ></script> <script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.3/dist/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin=anonymous ></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin=anonymous ></script> <div class=container-fluid  id=top-alert > <div class="alert alert-dark alert-dismissible mb-0" role=alert > <p class=text-center > <a href="https://youtu.be/yHiyJQdWBY8">Check out the latest talk: "The Continuing Advancements of Scientific Machine Learning (SciML)"</a> </p> <!-- <button type=button  class=close  data-dismiss=alert  aria-label=Close > <span aria-hidden=true >&times;</span> --> </button> </div> </div> <header> <nav class="navbar navbar-expand-lg navbar-light"> <a class=navbar-brand  href="/">Home</a> <button class=navbar-toggler  type=button  data-toggle=collapse  data-target="#navbarSupportedContent" aria-controls=navbarSupportedContent  aria-expanded=false  aria-label="Toggle navigation"> <span class=navbar-toggler-icon ></span> </button> <div class="collapse navbar-collapse" id=navbarSupportedContent > <ul class="navbar-nav mr-auto"> <li class="nav-item active"> <a class=nav-link  href="https://docs.sciml.ai/">Documentation</a> <li class=nav-item > <a class=nav-link  href="/news/">News</a> <li class=nav-item > <a class=nav-link  href="/roadmap/">Roadmap</a> <li class=nav-item > <a class=nav-link  href="/citing/">Citing</a> <li class=nav-item > <a class=nav-link  href="/showcase/">Showcase</a> <li class=nav-item > <a class=nav-link  href="https://benchmarks.sciml.ai/">Benchmarks</a> <li class=nav-item > <a class=nav-link  href="https://github.com/SciML/">GitHub</a> <li class="nav-item dropdown"> <a class="nav-link dropdown-toggle" href="#" id=navbarDropdownMenuLink  role=button  data-toggle=dropdown  aria-haspopup=true  aria-expanded=false > Community </a> <div class=dropdown-menu  aria-labelledby=navbarDropdownMenuLink > <a class=dropdown-item  href="/community/">Community Home</a> <a class=dropdown-item  href="/governance/">Governance</a> <a class=dropdown-item  href="/coc/">Code of Conduct</a> <a class=dropdown-item  href="/challenge/">Challenges</a> <a class=dropdown-item  href="/dev/">Developer Programs</a> </div> <li class=nav-item > <a class=nav-link  href="https://juliahub.com/company/contact-us-sciml"> Commercial Support </a> <li class=nav-item > <a class=nav-link  href="https://numfocus.org/donate-to-sciml"><i class="bi bi-heart"></i> Donate</a> </ul> </div> </nav> </header> <div class=franklin-content ><h1 id=why_we_deprecated_nlsolvejl_for_nonlinearsolvejl_for_solving_nonlinear_systems_in_julia ><a href="#why_we_deprecated_nlsolvejl_for_nonlinearsolvejl_for_solving_nonlinear_systems_in_julia" class=header-anchor >Why we deprecated NLsolve.jl for NonlinearSolve.jl for Solving Nonlinear Systems in Julia</a></h1> <p>In SciML, we have deprecated all direct NLsolve.jl interfaces to instead only support the NonlinearSolve.jl interfaces. This fixes a bunch of issues, both in terms of bugs and correctness, and reduces the support surface. We recommend that all downstream users update to make use of the NonlinearSolve.jl as well.</p> <h2 id=introduction_video_to_nonlinearsolvejl ><a href="#introduction_video_to_nonlinearsolvejl" class=header-anchor >Introduction Video to NonlinearSolve.jl</a></h2> <iframe width=560  height=315  src="https://www.youtube.com/embed/O-2F8fBuRRg?si=6GGlCfzGrXL--YI2" title="YouTube video player" frameborder=0  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> <h2 id=upgrade_path ><a href="#upgrade_path" class=header-anchor >Upgrade Path</a></h2> <p>As a direct upgrade path, NonlinearSolve.jl wraps the NLsolve.jl solvers. To use the wrapper, simply do <code>using NLsolve</code> and use the <code>NLsolveJL&#40;&#41;</code> solver in the <code>solve</code> call. This looks like:</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> NonlinearSolve, NLsolve
f(u, p) = u .* u .- p
u0 = [<span class=hljs-number >1.0</span>, <span class=hljs-number >1.0</span>]
p = <span class=hljs-number >2.0</span>
prob = NonlinearProblem(f, u0, p)
sol = solve(prob, NLsolveJL())</code></pre> <p>This can be used to update to the NonlinearSolve.jl interface while retaining exactly the same solver which can make the transition easier. However, through the NonlinearSolve.jl interface one can then explore other solves, many of which achieve higher performance and robustness than NLsolve.jl.</p> <h2 id=reasons_for_changing_to_nonlinearsolvejl ><a href="#reasons_for_changing_to_nonlinearsolvejl" class=header-anchor >Reasons for Changing to NonlinearSolve.jl</a></h2> <p>NLsolve.jl was widely used in the SciML ecosystem from around 2016 all the way through to 2023, what changed so that now all of those interfaces will update to the new interface? This comes from a combination of factors. Here&#39;s a subset of the total discussion.</p> <h3 id=improvements_to_performance_and_robustness ><a href="#improvements_to_performance_and_robustness" class=header-anchor >Improvements to Performance and Robustness</a></h3> <p>NonlinearSolve.jl solves some of the performance issues of NLsolve.jl. NLsolve.jl did not have caching interfaces and even its direct solve interface had more overhead than is necessary for many problems, which is demonstrated in the <a href="https://docs.sciml.ai/SciMLBenchmarksOutput/stable/">SciMLBenchmarks</a>. While NLsolve.jl does have a good showing in the benchmarks in comparison to prior tools such as CMINPACK &#40;i.e. SciPy&#41;, NonlinearSolve.jl eeks out an extra level of performance across the board, and many new robust methods.</p> <p><img src="https://private-user-images.githubusercontent.com/1814174/298835853-ec2eb0ee-2e9a-4c27-9a6c-aa9b1fad7eca.png?jwt&#61;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDU5OTQxMTksIm5iZiI6MTcwNTk5MzgxOSwicGF0aCI6Ii8xODE0MTc0LzI5ODgzNTg1My1lYzJlYjBlZS0yZTlhLTRjMjctOWE2Yy1hYTliMWZhZDdlY2EucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDEyMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDAxMjNUMDcxMDE5WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YmFjYmYyYjY5YzVlNTE0NDc1YmFkZDU3MTMyMjliMGI2ODBmNDgwZTkzM2U1M2U4YTQ5NjdhOTg2MDE3NWYxYyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.k12Hi7AaogHM1RPxssuXzZU4hgGh2VKbH3Cueuw3YxA" alt="" /></p> <h3 id=proper_handling_of_sparsity_and_linear_solvers ><a href="#proper_handling_of_sparsity_and_linear_solvers" class=header-anchor >Proper Handling of Sparsity and Linear Solvers</a></h3> <p>NLsolve.jl allows for supplying a sparse matrix, but it does not fully make use of the sparsity. For example, it still computes the Jacobian matrix as a complete dense object. NonlinearSolve.jl makes use of <a href="https://github.com/JuliaDiff/SparseDiffTools.jl">SparseDiffTools.jl</a> in order to perform matrix coloring and construct sparsity-specific differentiation passes. This can change the number of calls to <code>f</code> in order to calculate a Jacobian from O&#40;n&#41; to small constant O&#40;1&#41; in many important cases, for example the calculation of a tridiagonal Jacobian goes from the number of columns to to simply 3 <code>f</code> calls with this change.</p> <p>Additionally, NLsolve.jl did not integrate with <a href="https://github.com/SciML/LinearSolve.jl">LinearSolve.jl</a> which made it much more difficult to swap out to the correct linear solver. This also means that the improved defaults of LinearSolve.jl are not applied to the user&#39;s function. For example, on Mac M-series chips it&#39;s much faster to use AppleAccelerate BLAS backends for the LU-factorization but NLsolve.jl uses OpenBLAS by default instead. On x86 platforms it defaults to OpenBLAS instead of directly interfacing with the MKL_jll binaries, which is a major slowdown on any Intel or AMD CPU which is not an AMD EPYC. LinearSolve.jl&#39;s defaulting system accounts for these nuanances, and this alone can account for a nearly 2x performance difference <a href="https://github.com/SciML/LinearSolve.jl/issues/357#issuecomment-1669714631">as demonstrated by many user benchmarks</a>.</p> <p><img src="https://github.com/SciML/LinearSolve.jl/issues/357#issuecomment-1669714631" alt="" /></p> <p>Users of NLsolve.jl are required to know to <code>using AppleAccelerate</code> or <code>using MKL</code> based on what is the optimal backend given their CPU. However, we have found over the years that most users do not know what BLAS/LAPACK is and would prefer the library developers do CPU-specific optimizations in the library itself, and this change now to using NonlinearSolve.jl now takes that burden from the user to the library developer &#40;it can be overriden, but the defaults try to be smart&#41;.</p> <h3 id=automatic_differentiation_integration ><a href="#automatic_differentiation_integration" class=header-anchor >Automatic Differentiation Integration</a></h3> <p>Automatic differentation of a nonlinear solver can be much smart. For mathematical details, see <a href="https://arxiv.org/abs/2201.12240">this paper</a>. At a high level, what is meant by this is that calculating the derivative of the solution to a nonlinear system does not require differentiating the solver and instead can be done in a single step.</p> <p>NLsolve.jl does not integrate with automatic differenitation libraries. NonlinearSolve.jl integrates at a very deep level, having a defaulting system on the choice of vjp in order to achieve performance and allow for compatability with the standard mutable function form, and ensuring performance. Here is NonlinearSolve.jl building a loss function defined by the sum of the solution vector to the nonlinear system and differentiating that loss function with respect to the parameters that define the nonlinear system:</p> <pre><code class="julia hljs">u0 = [<span class=hljs-number >0.0</span>]
p = [<span class=hljs-number >2.0</span>, <span class=hljs-number >1.0</span>]
prob = NonlinearProblem((du, u, p) -&gt; du[<span class=hljs-number >1</span>] = u[<span class=hljs-number >1</span>] - p[<span class=hljs-number >1</span>] + p[<span class=hljs-number >2</span>], u0, p)

<span class=hljs-keyword >function</span> test_loss(p, prob; alg = NewtonRaphson())
    _prob = remake(prob, p = p)
    sol = sum(solve(_prob, alg))
    <span class=hljs-keyword >return</span> sol
<span class=hljs-keyword >end</span>
dp1 = Zygote.gradient(p -&gt; test_loss(p, prob), p)[<span class=hljs-number >1</span>]</code></pre> <p>Note that this is using the O&#40;1&#41;-backpropagation adjoint rule, also known as &quot;implicit differentiation&quot;. There&#39;s no special packages required to make this work, it just works.</p> <p>This fixes many issues with nonlinear solver integration into many downstream libraries as AD support is a generally crucial feature throughout SciML. And note that this is generic to the algorithm, and thus the best way to make NLsolve.jl compatible with AD is to simply use it through the NonlinearSolve.jl interface, which is why for upgrade and compatability reasons this is always done during the deprecation process.</p> <p>We note that this applies to forward-mode AD as well. NonlinearSolve.jl has special integration with ForwardDiff to ensure that the AD system does not differentiate the solver and instead applies a forward implicit differentiation rule automatically, improving the performance. This removes the nested differentiation required in the Jacobian calculations, since naively it would differentiate the differentiation, which is a very expensive process that is simply eliminated.</p> <h3 id=no_allocation_and_static_compilation ><a href="#no_allocation_and_static_compilation" class=header-anchor >No Allocation and Static Compilation</a></h3> <p>NonlinearSolve.jl has a no-allocation and static compilation compatible mode via the SimpleNonlinearSolve.jl set of solvers. All you have to do is swap out the solver and ensure you&#39;re using static arrays and numbers:</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> SimpleNonlinearSolve, StaticArrays

f(u, p) = u .* u .- p
u0 = SA[<span class=hljs-number >1.0</span>, <span class=hljs-number >1.0</span>]
p = <span class=hljs-number >2.0</span>
prob = NonlinearProblem(f, u0, p)
sol = solve(prob, SimpleNewtonRaphson())</code></pre> <p>and it compiles to a purely-static solve with 0 allocations. This can be used in GPU kernels, static binary builds, and many other applications that want a very fast and simple to compile nonlinear solver. Importantly, this gives all of these features to the nonlinear solver without changing the interface, and is thus a key piece required in the downstream GPU compatability of many SciML libraries. The need for this feature alone is what caused the NonlinearSolve.jl project to start, and thus it&#39;s a highly-tested and central part of why we are deprecating all of the NLsolve.jl interfaces in favor of now only using the NonlinearSolve.jl ones.</p> <h3 id=gpu_compatibility ><a href="#gpu_compatibility" class=header-anchor >GPU Compatibility</a></h3> <p>NLsolve.jl had spotty compatability with GPUs. It did not have comprehensive GPU support, for example ensuring it generates appropriate sparse matrices on the GPU if a sparse matrix is supplied, ensure that every internal operation is broadcasted together to reduce the number of GPU kernels, etc. But most importantly, it did not test GPU support as part of its CI processes so the GPU support that it did have was not robust. With NonlinearSolve.jl being regularly used in DeepEquilibriumNetworks, it is a regular use case to mix it with automatic differentiation, neural networks, and GPUs. Therefore these use cases are much more battle-tested and captured in CI/CD processes.</p> <h3 id=unification_of_interfaces ><a href="#unification_of_interfaces" class=header-anchor >Unification of Interfaces</a></h3> <p>Finally, NonlinearSolve.jl unifies the interface with the rest of SciML. Just like everything else, this makes the process simply <code>NonlinearProblem</code> then <code>solve</code>. Passing algorithms is you just pass the struct, i.e. <code>TrustRegion&#40;&#41;</code>. The documentation is all <a href="https://docs.sciml.ai/NonlinearSolve/stable/">in the SciMLDocs</a>. This makes the whole API much more streamlined and simple in comparison to having NLsolve.jl around, where suddenly algorithm choices for the nonlinear solver were <code>:trustregion</code>, something foreign to the rest of SciML.</p> <p>This makes the interfaces easier to document to the user. When NonlinearSolve.jl is used in a downstream component like an ODE solver, we can simply say &quot;provide a nonlinear solver from NonlinearSolve.jl. For more information, see the NonlinearSolve.jl documentation&quot;, and it will have a clear flow in the same docs system and a clear flow to similar syntax to the user. This unification and integration cannot be understated.</p> <h2 id=conclusion ><a href="#conclusion" class=header-anchor >Conclusion</a></h2> <p>All interfaces in SciML which previously used NLsolve.jl are now deprecated for NonlinearSolve.jl. Any use of the old interfaces will throw a warning to update. The upgrade process is straightforward and through the wrapper functionality. This change improves performance, robustness, CI/CD testing, sparsity handling, GPU support, automatic differentiation, no allocation modes, and static compilation. As a result, it achieves some of the major goals of the SciML organization, i.e. ensuring compatability of numerical solvers to the vast array of alternative applications and connections to machine learning without requiring that the user do anything special. Therefore, we are extremely happy with this change and hope all users will be too.</p> <!-- Footer--> <footer class="footer bg-light"> <div class=container > <div class=row > <div class="col-lg-6 h-100 text-center text-lg-start my-auto"> <ul class="list-inline mb-2"> <li class=list-inline-item ><a href="/community">Contact</a> <!-- <li class=list-inline-item ><a href="#!">Terms of Use</a> <li class=list-inline-item ><a href="#!">Privacy Policy</a> --> </ul> <p class="text-muted small mb-4 mb-lg-0">Website powered by <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia</a> programming language. &copy; SciML 2022. All Rights Reserved.</p> <p class="text-muted small mb-4 mb-lg-0">Edit on <a href="https://github.com/SciML/sciml.ai">GitHub</a></p> </div> <div class="col-lg-6 h-100 text-center text-lg-end my-auto"> <ul class="list-inline mb-0"> <li class="list-inline-item me-4"> <a href="https://github.com/SciML"><i class="bi-github fs-3"></i></a> <li class="list-inline-item me-4"> <a href="https://twitter.com/SciML_Org"><i class="bi-twitter fs-3"></i></a> <li class=list-inline-item > <a href="https://www.linkedin.com/company/the-julia-language"><i class="bi-linkedin fs-3"></i></a> </ul> </div> </div> </div> </footer> </div>