<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <meta property="og:title" content="SciML: Open Source Software for Scientific Machine Learning"> <meta property="og:description" content="Open Source Software for Scientific Machine Learning"> <meta property="og:image" content="https://sciml.ai/assets/SciMLGitHubPreview.png"> <meta property="og:url" content="https://sciml.ai"> <meta name="twitter:title" content=SciML > <meta name="twitter:description" content="Open Source Software for Scientific Machine Learning"> <meta name="twitter:image" content="https://sciml.ai/assets/SciMLGitHubPreview.png"> <meta name="twitter:card" content=summary_large_image > <!-- Favicon--> <link rel=icon  type="image/x-icon" href="assets/favicon.png" /> <!-- Bootstrap icons--> <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css" rel=stylesheet  type="text/css" /> <link rel=stylesheet  href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.8.1/font/bootstrap-icons.css"> <!-- Google fonts--> <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic" rel=stylesheet  type="text/css" /> <!-- Core theme CSS (includes Bootstrap)--> <link href="./css/styles.css" rel=stylesheet  /> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/styles.css"> <link rel=stylesheet  href="/css/hypertext.css"> <link rel=icon  href="/assets/favicon.png"> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-90474609-2"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-90474609-2'); </script> <title> DifferentialEquations.jl v6.11.0: Universal Differential Equation Overhaul </title> <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin=anonymous ></script> <script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.3/dist/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin=anonymous ></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin=anonymous ></script> <div class=container-fluid  id=top-alert > <div class="alert alert-dark alert-dismissible mb-0" role=alert > <p class=text-center > <a href="https://youtu.be/yHiyJQdWBY8">Check out the latest talk: "The Continuing Advancements of Scientific Machine Learning (SciML)"</a> </p> <!-- <button type=button  class=close  data-dismiss=alert  aria-label=Close > <span aria-hidden=true >&times;</span> --> </button> </div> </div> <header> <nav class="navbar navbar-expand-lg navbar-light"> <a class=navbar-brand  href="/">Home</a> <button class=navbar-toggler  type=button  data-toggle=collapse  data-target="#navbarSupportedContent" aria-controls=navbarSupportedContent  aria-expanded=false  aria-label="Toggle navigation"> <span class=navbar-toggler-icon ></span> </button> <div class="collapse navbar-collapse" id=navbarSupportedContent > <ul class="navbar-nav mr-auto"> <li class="nav-item active"> <a class=nav-link  href="https://docs.sciml.ai/">Documentation</a> <li class=nav-item > <a class=nav-link  href="/news/">News</a> <li class=nav-item > <a class=nav-link  href="/roadmap/">Roadmap</a> <li class=nav-item > <a class=nav-link  href="/citing/">Citing</a> <li class=nav-item > <a class=nav-link  href="/showcase/">Showcase</a> <li class=nav-item > <a class=nav-link  href="https://benchmarks.sciml.ai/">Benchmarks</a> <li class=nav-item > <a class=nav-link  href="https://github.com/SciML/">GitHub</a> <li class="nav-item dropdown"> <a class="nav-link dropdown-toggle" href="#" id=navbarDropdownMenuLink  role=button  data-toggle=dropdown  aria-haspopup=true  aria-expanded=false > Community </a> <div class=dropdown-menu  aria-labelledby=navbarDropdownMenuLink > <a class=dropdown-item  href="/community/">Community Home</a> <a class=dropdown-item  href="/governance/">Governance</a> <a class=dropdown-item  href="/coc/">Code of Conduct</a> <a class=dropdown-item  href="/challenge/">Challenges</a> <a class=dropdown-item  href="/dev/">Developer Programs</a> </div> <li class=nav-item > <a class=nav-link  href="https://juliahub.com/company/contact-us-sciml"> Commercial Support </a> <li class=nav-item > <a class=nav-link  href="https://numfocus.org/donate-to-sciml"><i class="bi bi-heart"></i> Donate</a> </ul> </div> </nav> </header> <div class=franklin-content ><h1 id=differentialequationsjl_v6110_universal_differential_equation_overhaul ><a href="#differentialequationsjl_v6110_universal_differential_equation_overhaul" class=header-anchor >DifferentialEquations.jl v6.11.0: Universal Differential Equation Overhaul</a></h1> <p>After the release of the paper <a href="https://arxiv.org/abs/2001.04385">Universal Differential Equations for Scientific Machine Learning</a>, we have had very good feedback and have seen plenty of new users joining the Julia differential equation ecosystem and utilizing the tools for scientific machine learning. A lot of our work in this last release focuses around these capability, mixing with GPU support and global sensitivity analysis to augment the normal local tools of SciML.</p> <h2 id=1000_stars_for_differentialequationsjl ><a href="#1000_stars_for_differentialequationsjl" class=header-anchor >1,000 Stars for DifferentialEquations.jl&#33;</a></h2> <p>Before the bigger updates, I wanted to announce that DifferentialEquations.jl surpassed the 1,000 star milestone in this round. This is very helpful for the community as an indicator of community utility. If you haven&#39;t done so yet, please <a href="https://github.com/JuliaDiffEq/DifferentialEquations.jl">star DifferentialEquations.jl</a> as it is a valuble indicator for future grants and funding for student projects.</p> <h2 id=local_sensitivity_analysis_overhaul_concrete_solve_and_sensealg ><a href="#local_sensitivity_analysis_overhaul_concrete_solve_and_sensealg" class=header-anchor >Local Sensitivity Analysis Overhaul: <code>concrete_solve</code> and <code>sensealg</code></a></h2> <p>With major help from Yingbo Ma &#40;@YingboMa&#41;, we have overhauled our sensitivity analysis algorithms to give a lot more choice and implementation flexibility. While all of the lower level interface is still in place, a new higher level interface will make users especially happy. This interface is <code>concrete_solve</code>. It&#39;s a version of <code>solve</code> &#40;limitation: no post-solution interpolation&#41; which explicitly takes in <code>u0</code> and <code>p</code>, and is setup with Zygote to automatically utilize our built-in <code>SensitivityAlgoritm</code> methods whether Zygote &#40;or any ChainRules.jl-based AD system&#41; asks for a gradient. For example:</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> DiffEqSensitivity, OrdinaryDiffEq, Zygote

<span class=hljs-keyword >function</span> fiip(du,u,p,t)
  du[<span class=hljs-number >1</span>] = dx = p[<span class=hljs-number >1</span>]*u[<span class=hljs-number >1</span>] - p[<span class=hljs-number >2</span>]*u[<span class=hljs-number >1</span>]*u[<span class=hljs-number >2</span>]
  du[<span class=hljs-number >2</span>] = dy = -p[<span class=hljs-number >3</span>]*u[<span class=hljs-number >2</span>] + p[<span class=hljs-number >4</span>]*u[<span class=hljs-number >1</span>]*u[<span class=hljs-number >2</span>]
<span class=hljs-keyword >end</span>
p = [<span class=hljs-number >1.5</span>,<span class=hljs-number >1.0</span>,<span class=hljs-number >3.0</span>,<span class=hljs-number >1.0</span>]; u0 = [<span class=hljs-number >1.0</span>;<span class=hljs-number >1.0</span>]
prob = ODEProblem(fiip,u0,(<span class=hljs-number >0.0</span>,<span class=hljs-number >10.0</span>),p)
sol = concrete_solve(prob,Tsit5())</code></pre> <p>solves the equation, while:</p> <pre><code class="julia hljs">du0,dp = Zygote.gradient((u0,p)-&gt;sum(concrete_solve(prob,Tsit5(),u0,p,saveat=<span class=hljs-number >0.1</span>,sensealg=QuadratureAdjoint())),u0,p)</code></pre>
<p>computes <code>du0</code> and <code>dp</code>: the gradient of the cost function with respect to the initial condition and parameters. Notice here we have a choice of <code>sensealg</code>, which allows the choice of a sensitivity analysis method for Zygote to use. The choices are vast and growing, with each having pros and cons. You can ask it to use forward sensitivity analysis, forward mode AD, Tracker.jl, O&#40;1&#41; adjoints via backsolve, <strong>checkpointed adjoints</strong>, etc. all just by changing the <code>sensealg</code> keyword argument. Thus this is the first system to offer such flexibility to allow for the most efficient gradient calculations for a specific problem to occur.</p>
<p>We&#39;ve seen some pretty massive performance and stability gains by utilizing this system&#33;</p>
<h2 id=diffeqflux_overhaul_zygote_support_sciml_train_interface_and_fast_layers ><a href="#diffeqflux_overhaul_zygote_support_sciml_train_interface_and_fast_layers" class=header-anchor >DiffEqFlux Overhaul: Zygote Support, <code>sciml_train</code> Interface, and Fast Layers</a></h2>
<p>Given the workflows that we saw in <a href="https://arxiv.org/abs/2001.04385">the UDE paper</a>, we have overhauled DiffEqFlux. The new interface, <code>sciml_train</code>, is more suitable to scientific machine learning. We have introduced the <code>Fast</code> layer setup, i.e. <code>FastChain</code> and <code>FastDense</code>, which give a 10x speed improvement over Flux.jl neural architectures by avoiding expensive restructure/destructure calls. Additionally, <code>sciml_train</code> links not just to the Flux.jl deep learning optimizer library, but also to Optim.jl for stability-enhanced methods like L-BFGS. Lastly, this new interface has explicit parameters, something that has helped fix a lot of issues users have had with the interface. Together, we can train a neural ODE in around 30 seconds in this example that mixes ADAM and BFGS optimizers:</p>
<pre><code class="julia hljs"><span class=hljs-keyword >using</span> DiffEqFlux, OrdinaryDiffEq, Flux, Optim, Plots

u0 = <span class=hljs-built_in >Float32</span>[<span class=hljs-number >2.</span>; <span class=hljs-number >0.</span>]
datasize = <span class=hljs-number >30</span>
tspan = (<span class=hljs-number >0.0f0</span>,<span class=hljs-number >1.5f0</span>)

<span class=hljs-keyword >function</span> trueODEfunc(du,u,p,t)
    true_A = [-<span class=hljs-number >0.1</span> <span class=hljs-number >2.0</span>; -<span class=hljs-number >2.0</span> -<span class=hljs-number >0.1</span>]
    du .= ((u.^<span class=hljs-number >3</span>)&#x27;true_A)&#x27;
<span class=hljs-keyword >end</span>
t = range(tspan[<span class=hljs-number >1</span>],tspan[<span class=hljs-number >2</span>],length=datasize)
prob = ODEProblem(trueODEfunc,u0,tspan)
ode_data = <span class=hljs-built_in >Array</span>(solve(prob,Tsit5(),saveat=t))

dudt2 = FastChain((x,p) -&gt; x.^<span class=hljs-number >3</span>,
            FastDense(<span class=hljs-number >2</span>,<span class=hljs-number >50</span>,tanh),
            FastDense(<span class=hljs-number >50</span>,<span class=hljs-number >2</span>))
n_ode = NeuralODE(dudt2,tspan,Tsit5(),saveat=t)

<span class=hljs-keyword >function</span> predict_n_ode(p)
  n_ode(u0,p)
<span class=hljs-keyword >end</span>

<span class=hljs-keyword >function</span> loss_n_ode(p)
    pred = predict_n_ode(p)
    loss = sum(abs2,ode_data .- pred)
    loss,pred
<span class=hljs-keyword >end</span>

loss_n_ode(n_ode.p) <span class=hljs-comment ># n_ode.p stores the initial parameters of the neural ODE</span>

cb = <span class=hljs-keyword >function</span> (p,l,pred;doplot=<span class=hljs-literal >false</span>) <span class=hljs-comment >#callback function to observe training</span>
  display(l)
  <span class=hljs-comment ># plot current prediction against data</span>
  <span class=hljs-keyword >if</span> doplot
    pl = scatter(t,ode_data[<span class=hljs-number >1</span>,:],label=<span class=hljs-string >&quot;data&quot;</span>)
    scatter!(pl,t,pred[<span class=hljs-number >1</span>,:],label=<span class=hljs-string >&quot;prediction&quot;</span>)
    display(plot(pl))
  <span class=hljs-keyword >end</span>
  <span class=hljs-keyword >return</span> <span class=hljs-literal >false</span>
<span class=hljs-keyword >end</span>

<span class=hljs-comment ># Display the ODE with the initial parameter values.</span>
cb(n_ode.p,loss_n_ode(n_ode.p)...)

res1 = DiffEqFlux.sciml_train(loss_n_ode, n_ode.p, ADAM(<span class=hljs-number >0.05</span>), cb = cb, maxiters = <span class=hljs-number >300</span>)
cb(res1.minimizer,loss_n_ode(res1.minimizer)...;doplot=<span class=hljs-literal >true</span>)
res2 = DiffEqFlux.sciml_train(loss_n_ode, res1.minimizer, LBFGS(), cb = cb)
cb(res2.minimizer,loss_n_ode(res2.minimizer)...;doplot=<span class=hljs-literal >true</span>)</code></pre>
<h2 id=sdes_and_ad_on_diffeqgpujl ><a href="#sdes_and_ad_on_diffeqgpujl" class=header-anchor >SDEs and AD on DiffEqGPU.jl</a></h2>
<p><a href="https://github.com/JuliaDiffEq/DiffEqGPU.jl">DiffEqGPU.jl, the library for automated parallelization of small differential equations across GPUs</a>, now supports SDEs and ForwardDiff dual numbers. This means you can use adaptive SDE solvers to solve 100,000 simultaneous SDEs on GPUs, or solve ODEs defined by dual numbers in order to do forward sensitivity analysis of many parameters at once. Once again, the interface is as simple as adding <code>EnsembleGPUArray&#40;&#41;</code> to your ensemble solve, essentially no code change is required to make use of these features&#33;</p>
<h2 id=global_sensitivity_analysis_overhaul_common_interface_and_parallelism ><a href="#global_sensitivity_analysis_overhaul_common_interface_and_parallelism" class=header-anchor >Global Sensitivity Analysis Overhaul: Common interface and Parallelism</a></h2>
<p>Thanks to Vaibhav Dixit &#40;@vaibhavdixit02&#41;, we now have a new interface for global sensitivity analysis which allows for specifying a function that is compatible with all forms of GSA and allows for parallelism. For example, we can look at the global sensitivity of the mean and the maximum of the Lotka-Volterra ODE by defining a function of the parmeters <code>p</code>:</p>
<pre><code class="julia hljs"><span class=hljs-keyword >using</span> DiffEqSensitivity, Statistics, OrdinaryDiffEq <span class=hljs-comment >#load packages</span>
<span class=hljs-keyword >function</span> f(du,u,p,t)
  du[<span class=hljs-number >1</span>] = p[<span class=hljs-number >1</span>]*u[<span class=hljs-number >1</span>] - p[<span class=hljs-number >2</span>]*u[<span class=hljs-number >1</span>]*u[<span class=hljs-number >2</span>] <span class=hljs-comment >#prey</span>
  du[<span class=hljs-number >2</span>] = -p[<span class=hljs-number >3</span>]*u[<span class=hljs-number >2</span>] + p[<span class=hljs-number >4</span>]*u[<span class=hljs-number >1</span>]*u[<span class=hljs-number >2</span>] <span class=hljs-comment >#predator</span>
<span class=hljs-keyword >end</span>
u0 = [<span class=hljs-number >1.0</span>;<span class=hljs-number >1.0</span>]
tspan = (<span class=hljs-number >0.0</span>,<span class=hljs-number >10.0</span>)
p = [<span class=hljs-number >1.5</span>,<span class=hljs-number >1.0</span>,<span class=hljs-number >3.0</span>,<span class=hljs-number >1.0</span>]
prob = ODEProblem(f,u0,tspan,p)
t = collect(range(<span class=hljs-number >0</span>, stop=<span class=hljs-number >10</span>, length=<span class=hljs-number >200</span>))
f1 = <span class=hljs-keyword >function</span> (p)
  prob1 = remake(prob;p=p)
  sol = solve(prob1,Tsit5();saveat=t)
  [mean(sol[<span class=hljs-number >1</span>,:]), maximum(sol[<span class=hljs-number >2</span>,:])]
<span class=hljs-keyword >end</span></code></pre>
<p>And from here we can call <code>gsa</code>:</p>
<pre><code class="julia hljs">m = gsa(f1,Morris(total_num_trajectory=<span class=hljs-number >1000</span>,num_trajectory=<span class=hljs-number >150</span>),[[<span class=hljs-number >1</span>,<span class=hljs-number >5</span>],[<span class=hljs-number >1</span>,<span class=hljs-number >5</span>],[<span class=hljs-number >1</span>,<span class=hljs-number >5</span>],[<span class=hljs-number >1</span>,<span class=hljs-number >5</span>]])</code></pre>
<p>That&#39;s GSA with the Morris method. But now Sobol is one line away, and eFAST, etc. are all simple variations.</p>
<p>In addition, there is a parallel batching interface that works nicely with the Ensemble interface. All that happens is that <code>p</code> becomes a matrix where each row <code>p&#91;i,:&#93;</code> is a set of parameters. For example, the following does the same global sensitivity analysis but with Sobol sensitivity and automatic GPU parallelism:</p>
<pre><code class="julia hljs"><span class=hljs-keyword >using</span> DiffEqGPU

f1 = <span class=hljs-keyword >function</span> (p)
  prob_func(prob,i,repeat) = remake(prob;p=p[i,:])
  ensemble_prob = EnsembleProblem(prob,prob_func=prob_func)
  sol = solve(ensemble_prob,Tsit5(),EnsembleGPUArray();saveat=t)
  <span class=hljs-comment ># Now sol[i] is the solution for the ith set of parameters</span>
  out = zeros(size(p,<span class=hljs-number >1</span>),<span class=hljs-number >2</span>)
  <span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-number >1</span>:size(p,<span class=hljs-number >1</span>)
    out[i,<span class=hljs-number >1</span>] = mean(sol[i][<span class=hljs-number >1</span>,:])
    out[i,<span class=hljs-number >2</span>] = maximum(sol[i][<span class=hljs-number >2</span>,:])
  <span class=hljs-keyword >end</span>
  out
<span class=hljs-keyword >end</span>
sobol_result = gsa(f1,Sobol(),A,B,batch=<span class=hljs-literal >true</span>)</code></pre>
<h2 id=efast_global_sensitivity_analysis ><a href="#efast_global_sensitivity_analysis" class=header-anchor >eFAST Global Sensitivity Analysis</a></h2>
<p>A new global sensitivity analysis method with fast convergence, eFAST, has been added to the library. It works on the same <code>gsa</code> interface, so code using more traditional Sobol or Morris techniques can switch over to this faster converging method with just a few lines changed&#33;</p>
<h1 id=next_directions ><a href="#next_directions" class=header-anchor >Next Directions</a></h1>
<p>Here&#39;s some things to look forward to:</p>
<ul>
<li><p>Automated matrix-free finite difference PDE operators</p>

<li><p>Jacobian reuse efficiency in Rosenbrock-W methods</p>

<li><p>Native Julia fully implicit ODE &#40;DAE&#41; solving in OrdinaryDiffEq.jl</p>

<li><p>High Strong Order Methods for Non-Commutative Noise SDEs</p>

<li><p>Stochastic delay differential equations</p>

</ul>
<!-- Footer-->
<footer class="footer bg-light">
  <div class=container >
      <div class=row >
          <div class="col-lg-6 h-100 text-center text-lg-start my-auto">
              <ul class="list-inline mb-2">
                  
                  <li class=list-inline-item ><a href="/community">Contact</a>
                  <!-- <li class=list-inline-item ><a href="#!">Terms of Use</a>
                  <li class=list-inline-item ><a href="#!">Privacy Policy</a> -->
              </ul>
              <p class="text-muted small mb-4 mb-lg-0">Website powered by <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia</a> programming language. &copy; SciML 2022. All Rights Reserved.</p>
              <p class="text-muted small mb-4 mb-lg-0">Edit on <a href="https://github.com/SciML/sciml.ai">GitHub</a></p>

            </div>
          <div class="col-lg-6 h-100 text-center text-lg-end my-auto">
              <ul class="list-inline mb-0">
                  <li class="list-inline-item me-4">
                      <a href="https://github.com/SciML"><i class="bi-github fs-3"></i></a>
                  
                  <li class="list-inline-item me-4">
                      <a href="https://twitter.com/SciML_Org"><i class="bi-twitter fs-3"></i></a>
                  
                  <li class=list-inline-item >
                      <a href="https://www.linkedin.com/company/the-julia-language"><i class="bi-linkedin fs-3"></i></a>
                  
              </ul>
          </div>
      </div>
  </div>
</footer>
</div>