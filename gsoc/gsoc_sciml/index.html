<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <meta property="og:title" content=SciML > <meta property="og:description" content="Open Source Software for Scientific Machine Learning"> <meta property="og:image" content="https://sciml.ai/assets/SciMLGitHubPreview.png"> <meta property="og:url" content="https://sciml.ai"> <meta name="twitter:title" content=SciML > <meta name="twitter:description" content="Open Source Software for Scientific Machine Learning"> <meta name="twitter:image" content="https://sciml.ai/assets/SciMLGitHubPreview.png"> <meta name="twitter:card" content=summary_large_image > <!-- Favicon--> <link rel=icon  type="image/x-icon" href="assets/favicon.png" /> <!-- Bootstrap icons--> <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css" rel=stylesheet  type="text/css" /> <link rel=stylesheet  href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.8.1/font/bootstrap-icons.css"> <!-- Google fonts--> <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic" rel=stylesheet  type="text/css" /> <!-- Core theme CSS (includes Bootstrap)--> <link href="./css/styles.css" rel=stylesheet  /> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/hypertext.css"> <link rel=icon  href="/assets/favicon.png"> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-90474609-2"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-90474609-2'); </script> <div class=container-fluid  id=top-alert > <div class="alert alert-dark alert-dismissible mb-0" role=alert > <p class=text-center > SciMLCon 2022 is live now! <a href="https://scimlcon.org/2022/">Register and attend today (9 AM - 5 PM EST)</a> </p> <button type=button  class=close  data-dismiss=alert  aria-label=Close > <span aria-hidden=true >&times;</span> </button> </div> </div> <header> <nav class="navbar navbar-light bg-light static-top"> <div class=container > <a class="btn btn-primary" href="/" class=current >Home</a> <a class=navbar-brand  href="/news/">News</a> <a class=navbar-brand  href="/roadmap/">Roadmap</a> <a class=navbar-brand  href="/citing/">Citing</a> <a class=navbar-brand  href="/showcase/">Showcase</a> <a class=navbar-brand  href="/challenge/">Challenge Problems</a> <a class=navbar-brand  href="/community/">Community</a> <hr/> <a class=navbar-brand  href="/documentation/">Documentation</a> <a class=navbar-brand  href="/dev/">Dev Programs</a> <a class=navbar-brand  href="/governance/">Governance</a> <a class=navbar-brand  href="https://benchmarks.sciml.ai/">Benchmarks</a> <a class=navbar-brand  href="https://github.com/SciML/">Source Code</a> <a class=navbar-brand  href="https://numfocus.org/donate-to-sciml">Donate</a> </div> </nav> </header> <div class=franklin-content ><h1 id=sciml_scientific_machine_learning_projects_google_summer_of_code ><a href="#sciml_scientific_machine_learning_projects_google_summer_of_code" class=header-anchor >SciML Scientific Machine Learning Projects â€“ Google Summer of Code</a></h1> <h2 id=physics-informed_neural_networks_pinns_and_solving_differential_equations_with_deep_learning ><a href="#physics-informed_neural_networks_pinns_and_solving_differential_equations_with_deep_learning" class=header-anchor >Physics-Informed Neural Networks &#40;PINNs&#41; and Solving Differential Equations with Deep Learning</a></h2> <p>Neural networks can be used as a method for efficiently solving difficult partial differential equations. Recently this strategy has been dubbed <a href="https://www.sciencedirect.com/science/article/pii/S0021999118307125">physics-informed neural networks</a> and has seen a resurgence because of its efficiency advantages over classical deep learning. Efficient implementations from recent papers are being explored as part of the <a href="https://github.com/SciML/NeuralNetDiffEq.jl">NeuralNetDiffEq.jl</a> package. The <a href="https://github.com/SciML/NeuralNetDiffEq.jl/issues">issue tracker</a> contains links to papers which would be interesting new neural network based methods to implement and benchmark against classical techniques. Project work in this area includes:</p> <ul> <li><p><a href="https://github.com/SciML/NeuralNetDiffEq.jl/issues/71">Improved training strategies</a> for PINNs.</p> <li><p>Implementing new neural architectures that impose physical constraints like <a href="https://arxiv.org/pdf/2002.00021.pdf">divergence-free criteria</a>.</p> <li><p>Demonstrating large-scale problems solved by PINN training.</p> <li><p>Improving the speed and parallelization of PINN training routines.</p> </ul> <p>This project is good for both software engineers interested in the field of scientific machine learning and those students who are interested in perusing graduate research in the field.</p> <p><strong>Recommended Skills</strong>: Background knowledge in numerical analysis and machine learning.</p> <p><strong>Expected Results</strong>: New neural network based solver methods.</p> <p><strong>Mentors</strong>: <a href="https://github.com/ChrisRackauckas">Chris Rackauckas</a> and <a href="https://github.com/KirillZubov">Kirill Zubov</a></p> <p><strong>Expected Project Size</strong>: 175 hour or 350 hour depending on the chosen subtasks.</p> <p><strong>Difficulty</strong>: Easy to Hard depending on the chosen subtasks.</p> <h2 id=improvements_to_neural_and_universal_differential_equations ><a href="#improvements_to_neural_and_universal_differential_equations" class=header-anchor >Improvements to Neural and Universal Differential Equations</a></h2> <p><a href="https://arxiv.org/abs/1806.07366">Neural ordinary differential equations</a> have been shown to be a way to use machine learning to learn differential equation models. Further improvements to the methodology, like <a href="https://arxiv.org/abs/2001.04385">universal differential equations</a> have incorporated physical and biological knowledge into the system in order to make it a data and compute efficient learning method. However, there are many computational aspects left to explore. The purpose of this project is to enhance the universal differential equation approximation abilities of <a href="https://github.com/SciML/DiffEqFlux.jl">DiffEqFlux.jl</a>, adding features like:</p> <ul> <li><p>Improved adjoints for DAEs and SDEs</p> <li><p><a href="https://github.com/SciML/DiffEqFlux.jl/issues/173">Non-neural network universal approximators</a></p> <li><p>Various <a href="https://github.com/SciML/DiffEqFlux.jl/issues/133">improvements to</a> <a href="https://github.com/SciML/DiffEqFlux.jl/issues/118">minibatching</a></p> <li><p>Support for <a href="https://github.com/SciML/DiffEqFlux.jl/issues/48">second order ODEs &#40;i.e. symplectic integrators&#41;</a></p> <li><p><a href="https://github.com/SciML/DiffEqFlux.jl/issues/46">Continuous normalizing flows</a> and <a href="https://github.com/SciML/DiffEqFlux.jl/issues/47">FFJORD</a></p> </ul> <p>See the <a href="https://github.com/SciML/DiffEqFlux.jl/issues">DiffEqFlux.jl issue tracker</a> for full details.</p> <p>This project is good for both software engineers interested in the field of scientific machine learning and those students who are interested in perusing graduate research in the field.</p> <p><strong>Recommended Skills</strong>: Background knowledge in numerical analysis and machine learning.</p> <p><strong>Expected Results</strong>: New and improved methods for neural and universal differential equations.</p> <p><strong>Mentors</strong>: <a href="https://github.com/ChrisRackauckas">Chris Rackauckas</a></p> <p><strong>Expected Project Size</strong>: 175 hour or 350 hour depending on the chosen subtasks.</p> <p><strong>Difficulty</strong>: Medium to Hard depending on the chosen subtasks.</p> <h2 id=accelerating_optimization_via_machine_learning_with_surrogate_models_surrogatesjl ><a href="#accelerating_optimization_via_machine_learning_with_surrogate_models_surrogatesjl" class=header-anchor >Accelerating optimization via machine learning with surrogate models: Surrogates.jl</a></h2> <p>In many cases, when attempting to optimize a function <code>f&#40;p&#41;</code> each calculation of <code>f</code> is very expensive. For example, evaluating <code>f</code> may require solving a PDE or other applications of complex linear algebra. Thus, instead of always directly evaluating <code>f</code>, one can develop a surrogate model <code>g</code> which is approximately <code>f</code> by training on previous data collected from <code>f</code> evaluations. This technique of using a trained surrogate in place of the real function is called surrogate optimization and mixes techniques from machine learning to accelerate optimization.</p> <p>Advanced techniques <a href="https://www.cambridge.org/core/journals/acta-numerica/article/kernel-techniques-from-machine-learning-to-meshless-methods/00686923110F799A1537C4F02BBAAE8E">utilize radial basis functions</a> and Gaussian processes in order to interpolate to new parameters to estimate <code>f</code> in areas which have not been sampled. <a href="http&#37;3A&#37;2F&#37;2Fwww.ressources-actuarielles.net&#37;2FEXT&#37;2FISFA&#37;2F1226.nsf&#37;2F9c8e3fd4d8874d60c1257052003eced6&#37;2Fe7dc33e4da12c5a9c12576d8002e442b&#37;2F&#37;24FILE&#37;2FJones01.pdf">Adaptive training techniques</a> explore how to pick new areas to evaluate <code>f</code> to better hone in on global optima.</p> <p>The purpose of this project is to further improve Surrogates.jl by: adding new surrogate models, adding new optimization techniques, showcasing compatibility with the SciML ecosystem and fixing unwanted behaviour with some current surrogate models.</p> <p><strong>Recommended Skills</strong>: Background knowledge of standard machine learning, statistical, or optimization techniques. Strong knowledge of numerical analysis is helpful but not required.</p> <p><strong>Expected Results</strong>: Improving Surrogates.jl with new surrogate models and new optimization techniques.</p> <p><strong>Mentors</strong>: <a href="https:https://github.com/ludoro">Ludovico Bessi</a>, <a href="https://github.com/ChrisRackauckas">Chris Rackauckas</a></p> <p><strong>Expected Project Size</strong>: 175 hour or 350 hour depending on the chosen subtasks.</p> <p><strong>Difficulty</strong>: Medium to Hard depending on the chosen subtasks.</p> <h2 id=integration_of_fenicsjl_with_dolfin-adjoint_zygotejl_for_finite_element_scientific_machine_learning ><a href="#integration_of_fenicsjl_with_dolfin-adjoint_zygotejl_for_finite_element_scientific_machine_learning" class=header-anchor >Integration of FEniCS.jl with dolfin-adjoint &#43; Zygote.jl for Finite Element Scientific Machine Learning</a></h2> <p>Scientific machine learning requires mixing scientific computing libraries with machine learning. <a href="https://www.stochasticlifestyle.com/the-essential-tools-of-scientific-machine-learning-scientific-ml/">This blog post highlights how the tooling of Julia is fairly advanced in this field</a> compared to alternatives such as Python, but one area that has not been completely worked out is integration of automatic differentiation with partial differential equations. <a href="https://github.com/SciML/FEniCS.jl">FEniCS.jl</a> is a wrapper to the <a href="https://fenicsproject.org/">FEniCS</a> project for finite element solutions of partial differential equations. We would like to augment the Julia wrappers to allow for integration with Julia&#39;s automatic differentiation libraries like <a href="https://github.com/FluxML/Zygote.jl">Zygote.jl</a> by using <a href="http://www.dolfin-adjoint.org/en/release/">dolfin-adjoint</a>. This would require setting up this library for automatic installation for Julia users and writing adjoint passes which utilize this adjoint builder library. It would result in the first total integration between PDEs and neural networks.</p> <p><strong>Recommended Skills</strong>: A basic background in differential equations and Python. Having previous Julia knowledge is preferred but not strictly required.</p> <p><strong>Expected Results</strong>: Efficient and high-quality implementations of adjoints for Zygote.jl over FEniCS.jl functions.</p> <p><strong>Mentors</strong>: <a href="https://github.com/ChrisRackauckas">Chris Rackauckas</a></p> <p><strong>Expected Project Size</strong>: 350 hour.</p> <p><strong>Difficulty</strong>: Medium to Hard depending on the chosen subtasks.</p> <!-- Footer--> <footer class="footer bg-light"> <div class=container > <div class=row > <div class="col-lg-6 h-100 text-center text-lg-start my-auto"> <ul class="list-inline mb-2"> <li class=list-inline-item ><a href="/community">Contact</a> <!-- <li class=list-inline-item ><a href="#!">Terms of Use</a> <li class=list-inline-item ><a href="#!">Privacy Policy</a> --> </ul> <p class="text-muted small mb-4 mb-lg-0">Website powered by <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia</a> programming language. &copy; SciML 2022. All Rights Reserved.</p> <p class="text-muted small mb-4 mb-lg-0">Edit on <a href="https://github.com/SciML/sciml.ai">GitHub</a></p> </div> <div class="col-lg-6 h-100 text-center text-lg-end my-auto"> <ul class="list-inline mb-0"> <li class="list-inline-item me-4"> <a href="https://github.com/SciML"><i class="bi-github fs-3"></i></a> <li class="list-inline-item me-4"> <a href="https://twitter.com/SciML_Org"><i class="bi-twitter fs-3"></i></a> <li class=list-inline-item > <a href="https://www.linkedin.com/company/the-julia-language"><i class="bi-linkedin fs-3"></i></a> </ul> </div> </div> </div> </footer></div>